{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7slEwLkdyEWr"
      },
      "source": [
        "# Instrument-to-Instrument translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jvypA6-yOMt"
      },
      "source": [
        "ITI provides translations between image domains of solar instruments (image enhancement, super-resolution, cross-calibration, estimation of observables). This notebook provides two training examples of ITI.\n",
        "\n",
        "Colab offers free online computation power. The training requires an active GPU. This can be changed in the menu (Runtime -> Change runtime type -> Hardware accelerator -> GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and imports"
      ],
      "metadata": {
        "id": "WGCPnpmps6pD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oKAyFzdvTOi"
      },
      "outputs": [],
      "source": [
        "!pip install sunpy==3.0 zarr gcsfs\n",
        "!pip install git+https://github.com/RobertJaro/InstrumentToInstrument.git@v0.1.0\n",
        "!pip install git+https://github.com/vale-salvatelli/sdo-autocal_pub.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvzMl2FovYGx"
      },
      "outputs": [],
      "source": [
        "import gcsfs\n",
        "import zarr\n",
        "import dask.array as da\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from multiprocessing import get_context\n",
        "\n",
        "from sdo.datasets.sdo_dataset import SDO_Dataset\n",
        "from sdo.pytorch_utilities import create_dataloader\n",
        "\n",
        "from iti.data.editor import *\n",
        "from iti.data.dataset import BaseDataset, StackDataset, sdo_norms\n",
        "from iti.train.model import DiscriminatorMode\n",
        "from iti.trainer import Trainer, loop\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.colors import LogNorm\n",
        "from astropy.visualization import ImageNormalize, LinearStretch, AsinhStretch\n",
        "\n",
        "from sunpy.visualization.colormaps import cm\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from astropy import units as u\n",
        "from astropy.coordinates import SkyCoord\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download SDOML dataset"
      ],
      "metadata": {
        "id": "kEHTMUQQwYm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SDOML dataset is publicly available for download. The data is stored as compressed Numpy arrays."
      ],
      "metadata": {
        "id": "AdnZ1oUvtDem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this demo we use observations from 2011, where we select one observation per day. For practical applications all avaialable years should be considered (2010 - 2021).\n",
        "\n",
        "We use the HMI magnetograms as reference and select the corresponding EUV observations."
      ],
      "metadata": {
        "id": "4DUyKy1ztVTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcs = gcsfs.GCSFileSystem(access=\"read_only\")"
      ],
      "metadata": {
        "id": "zU-sKVnCBTJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load HMI data\n",
        "loc_hmi = \"fdl-sdoml-v2/sdomlv2_hmi.zarr/2011\"\n",
        "store = gcsfs.GCSMap(loc_hmi, gcs=gcs, check=False)\n",
        "root = zarr.group(store)\n",
        "\n",
        "hmi_times = root[\"Bx\"].attrs[\"T_OBS\"]\n",
        "sampling_step = len(hmi_times) // 365\n",
        "hmi_times = hmi_times[::sampling_step] # subsample\n",
        "hmi_times = pd.to_datetime(hmi_times, format='%Y.%m.%d_%H:%M:%S_TAI').to_pydatetime()\n",
        "\n",
        "hmi_Bx = da.from_array(root[\"Bx\"])[::sampling_step] # subsample\n",
        "hmi_By = da.from_array(root[\"By\"])[::sampling_step] # subsample\n",
        "hmi_Bz = da.from_array(root[\"Bz\"])[::sampling_step] # subsample"
      ],
      "metadata": {
        "id": "OHxsMqCvs93n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load AIA data\n",
        "loc = \"fdl-sdoml-v2/sdomlv2.zarr/2011\"\n",
        "store = gcsfs.GCSMap(loc, gcs=gcs, check=False)\n",
        "aia_root = zarr.group(store, synchronizer=zarr.ThreadSynchronizer())"
      ],
      "metadata": {
        "id": "dPw9-lR33j-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# align AIA data\n",
        "aia_keys = ['171A', '193A', '211A', '304A']# all keys: aia_root.array_keys()\n",
        "time_data_mapping = {t: [] for t in hmi_times}\n",
        "for key in aia_keys: \n",
        "  df = aia_root[key]\n",
        "  obs_times = pd.to_datetime(df.attrs['T_OBS'], format='%Y-%m-%dT%H:%M:%S.%fZ').to_pydatetime()\n",
        "  da_array = da.from_array(df)\n",
        "  for t in hmi_times:\n",
        "    if np.min(np.abs(obs_times - t)) > timedelta(minutes=15):\n",
        "      continue\n",
        "    idx = np.argmin(np.abs(obs_times - t))\n",
        "    time_data_mapping[t] += [da_array[idx]]\n"
      ],
      "metadata": {
        "id": "EV4PDwygw9b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our selection we donwload the data and save it as numpy arrays."
      ],
      "metadata": {
        "id": "1vZ1fjDYuDHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (d, aia_cube) in tqdm(enumerate(time_data_mapping.items()), desc='loading data cubes', total=len(hmi_times)):\n",
        "  if len(aia_cube) != len(aia_keys):\n",
        "    continue\n",
        "  save_path = 'data/%s.npy' % d.isoformat('T')\n",
        "  if os.path.exists(save_path):\n",
        "    continue\n",
        "  # subsample to 256x256\n",
        "  cube = np.stack([hmi_Bx[i, ::2, ::2], \n",
        "                   hmi_By[i, ::2, ::2], \n",
        "                   hmi_Bz[i, ::2, ::2], \n",
        "                   *[d[::2, ::2] for d in aia_cube]])\n",
        "  np.save(save_path, cube)"
      ],
      "metadata": {
        "id": "14GOos23jsIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training - EUV-to-304"
      ],
      "metadata": {
        "id": "XlS2yb7EuR8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first example we use the EUV channels 171, 193 and 211 to generate synthetic 304 observations. "
      ],
      "metadata": {
        "id": "Ckb5CvlFuMSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"sdo_to_sdo\"\n",
        "os.makedirs(base_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "0IkxlMwb75Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first create a data set that reads the numpy arrays and normalizes them to [-1, 1]."
      ],
      "metadata": {
        "id": "Em57umqcudbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_min = np.array([-1500, -1500, -1500, 0, 0, 0, 0])\n",
        "norm_max = np.array([1500, 1500, 1500, 2000, 2500, 2000, 1000])\n",
        "\n",
        "class SDODataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, channel_slice=(0, 7), **kwargs):\n",
        "        self.data = data\n",
        "        self.channel_slice = channel_slice\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = np.load(self.data[idx])\n",
        "        data = (data - norm_min[:, None, None]) / (norm_max - norm_min)[:, None, None]\n",
        "        data = data * 2 - 1\n",
        "        data[data > 1] = 1\n",
        "        data[data < -1] = -1\n",
        "        data = data[self.channel_slice[0]:self.channel_slice[1]]\n",
        "        return data"
      ],
      "metadata": {
        "id": "r9KsUX6Sufim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create two data sets:\n",
        "\n",
        "A(low-quality) --> channels 3 to 6 (171, 193, 211)\n",
        "\n",
        "B(high-quality) --> channels 3 to 7 (171, 193, 211, 304)\n",
        "\n",
        "\n",
        "Therefore, we synthesize the 304 channel in addition to the other channels. The advantage of this approach is that the 304 channel is generated to be consistent with the other channels."
      ],
      "metadata": {
        "id": "pODaDicouqJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob('data/*.npy')\n",
        "sdo_train_A = SDODataset(files, (3, 6))\n",
        "sdo_train_B = SDODataset(files, (3, 7))"
      ],
      "metadata": {
        "id": "UPGBx37rvBsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a basic logging to monitor the progress of our training."
      ],
      "metadata": {
        "id": "87Fr8K2Uvny8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"{0}/{1}.log\".format(base_dir, \"info_log\")),\n",
        "        logging.StreamHandler()\n",
        "    ])"
      ],
      "metadata": {
        "id": "vC7OwefcvKI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trainer is the central component of ITI. Here, we translate from dat with 3 channels to 4 channels. The discriminator mode uses a single discriminator for each channel and a separate discriminator for the combined set of channesls. Since we do not expect large instrumental noise we set the diversity training to 0. The layer normalization is important when dealing with image patches. For our application we use full-disk observations, which does not require a tracking of norm statistics. For the training with image patches the 'in_aff_rs' norm is suggested. "
      ],
      "metadata": {
        "id": "MHArNqkFvy2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(input_dim_a=3, input_dim_b=4, discriminator_mode=DiscriminatorMode.CHANNELS, lambda_diversity=0, norm='in_aff')"
      ],
      "metadata": {
        "id": "RNorSlR9vMsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For monitoring our progress we initialize callbacks that plot intermediate resutls and save the model state."
      ],
      "metadata": {
        "id": "MfBpvCYBwsko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_A=sdo_train_A\n",
        "ds_B=sdo_train_B\n",
        "num_workers=0\n",
        "\n",
        "trainer.cuda()\n",
        "trainer.train()\n",
        "start_it = trainer.resume(base_dir)\n",
        "\n",
        "# Init Callbacks\n",
        "from iti.callback import HistoryCallback, ProgressCallback, SaveCallback, PlotBAB, PlotABA, ValidationHistoryCallback\n",
        "history_callback = HistoryCallback(trainer, base_dir)\n",
        "progress_callback = ProgressCallback(trainer)\n",
        "save_callback = SaveCallback(trainer, base_dir)\n",
        "\n",
        "plot_settings = [\n",
        "    {\"cmap\": cm.sdoaia171, \"title\": \"AIA 171\", 'norm': ImageNormalize(vmin=-1, vmax=1, stretch=AsinhStretch(0.01))},\n",
        "    {\"cmap\": cm.sdoaia193, \"title\": \"AIA 193\", 'norm': ImageNormalize(vmin=-1, vmax=1, stretch=AsinhStretch(0.01))},\n",
        "    {\"cmap\": cm.sdoaia211, \"title\": \"AIA 211\", 'norm': ImageNormalize(vmin=-1, vmax=1, stretch=AsinhStretch(0.01))},\n",
        "    {\"cmap\": cm.sdoaia304, \"title\": \"AIA 304\", 'norm': ImageNormalize(vmin=-1, vmax=1, stretch=AsinhStretch(0.01))},\n",
        "]\n",
        "random_sample = [ds_A[i] for i in random.sample(range(len(ds_A)), 4)]\n",
        "plot_ABA_callback = PlotABA(random_sample, trainer, base_dir, log_iteration=100, plot_settings_A=plot_settings[:-1], plot_settings_B=plot_settings)\n",
        "plot_ABA_callback.call(0)\n",
        "\n",
        "random_sample = [ds_B[i] for i in random.sample(range(len(ds_B)), 4)]\n",
        "plot_BAB_callback = PlotBAB(random_sample, trainer, base_dir, log_iteration=100, plot_settings_A=plot_settings[:-1], plot_settings_B=plot_settings)\n",
        "plot_BAB_callback.call(0)\n",
        "\n",
        "callbacks = [plot_ABA_callback, plot_BAB_callback, history_callback, progress_callback, save_callback]\n",
        "# init data loaders\n",
        "B_iterator = loop(DataLoader(ds_B, batch_size=1, shuffle=True, num_workers=4, ))\n",
        "A_iterator = loop(DataLoader(ds_A, batch_size=1, shuffle=True, num_workers=4, ))"
      ],
      "metadata": {
        "id": "YhiDEw8GvT1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this we can start the main training loop, where randomly sample from our data sets. We iteratively use the trainer to update the generator and discrimintor networks. The results are automatically logged to the filesystem (`base_dir`)."
      ],
      "metadata": {
        "id": "hSPEOEBLw4pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start update cycle\n",
        "for it in range(start_it, 10000):\n",
        "    trainer.train()\n",
        "    #\n",
        "    x_a, x_b = next(A_iterator), next(B_iterator)\n",
        "    x_a, x_b = x_a.float().cuda().detach(), x_b.float().cuda().detach()\n",
        "    trainer.discriminator_update(x_a, x_b)\n",
        "    #\n",
        "    x_a, x_b = next(A_iterator), next(B_iterator)\n",
        "    x_a, x_b = x_a.float().cuda().detach(), x_b.float().cuda().detach()\n",
        "    trainer.generator_update(x_a, x_b)\n",
        "    torch.cuda.synchronize()\n",
        "    #\n",
        "    trainer.eval()\n",
        "    with torch.no_grad():\n",
        "      for callback in callbacks:\n",
        "          callback(it)"
      ],
      "metadata": {
        "id": "-0Frba7UvXHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training - EUV-to-Magnetogram"
      ],
      "metadata": {
        "id": "KHJuqIxIKkEX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJzB2QNq8Nql"
      },
      "outputs": [],
      "source": [
        "norm_min = np.array([-1500, -1500, -1500, 0, 0, 0, 0])\n",
        "norm_max = np.array([1500, 1500, 1500, 2000, 2500, 2000, 1000])\n",
        "\n",
        "class EUVDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, **kwargs):\n",
        "        self.data = data\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = np.load(self.data[idx])[3:]\n",
        "        data = (data - norm_min[3:, None, None]) / (norm_max - norm_min)[3:, None, None]\n",
        "        data = data * 2 - 1\n",
        "        data[data > 1] = 1\n",
        "        data[data < -1] = -1\n",
        "        return data\n",
        "\n",
        "class MagDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, **kwargs):\n",
        "        self.data = data\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = np.load(self.data[idx])\n",
        "        #data[:3] = np.flip(data[:3], axis=(2))\n",
        "        data = (data - norm_min[:, None, None]) / (norm_max - norm_min)[:, None, None]\n",
        "        data = data * 2 - 1\n",
        "        data[data > 1] = 1\n",
        "        data[data < -1] = -1\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrvIesokQCfz"
      },
      "outputs": [],
      "source": [
        "files = glob.glob('data/*.npy')\n",
        "sdo_train_A = EUVDataset(files)\n",
        "sdo_train_B = MagDataset(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y1iUaXM86PF"
      },
      "outputs": [],
      "source": [
        "base_dir = \"sdo_to_sdo\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Init model\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"{0}/{1}.log\".format(base_dir, \"info_log\")),\n",
        "        logging.StreamHandler()\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss96TfSsht89"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(input_dim_a=4, input_dim_b=7, discriminator_mode=DiscriminatorMode.CHANNELS, lambda_diversity=0, norm='in_aff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak-ZMXolWlv9"
      },
      "outputs": [],
      "source": [
        "base_dir = base_dir\n",
        "ds_A=sdo_train_A\n",
        "ds_B=sdo_train_B\n",
        "num_workers=0\n",
        "\n",
        "trainer.cuda()\n",
        "trainer.train()\n",
        "start_it = trainer.resume(base_dir)\n",
        "\n",
        "# Init Callbacks\n",
        "from iti.callback import HistoryCallback, ProgressCallback, SaveCallback, PlotBAB, PlotABA, ValidationHistoryCallback\n",
        "history_callback = HistoryCallback(trainer, base_dir)\n",
        "progress_callback = ProgressCallback(trainer)\n",
        "save_callback = SaveCallback(trainer, base_dir)\n",
        "\n",
        "plot_settings = [\n",
        "    {\"cmap\": 'gray', \"title\": \"Bx\", 'vmin': -1, 'vmax': 1},\n",
        "    {\"cmap\": 'gray', \"title\": \"By\", 'vmin': -1, 'vmax': 1},\n",
        "    {\"cmap\": 'gray', \"title\": \"Bz\", 'vmin': -1, 'vmax': 1},\n",
        "    {\"cmap\": cm.sdoaia171, \"title\": \"AIA 171\", 'vmin': -1, 'vmax': 1},\n",
        "    {\"cmap\": cm.sdoaia193, \"title\": \"AIA 193\", 'vmin': -1, 'vmax': 1},\n",
        "    {\"cmap\": cm.sdoaia211, \"title\": \"AIA 211\", 'vmin': -1, 'vmax': 1},\n",
        "    {\"cmap\": cm.sdoaia304, \"title\": \"AIA 304\", 'vmin': -1, 'vmax': 1},\n",
        "]\n",
        "random_sample = [ds_A[i] for i in random.sample(range(len(ds_A)), 4)]\n",
        "plot_ABA_callback = PlotABA(random_sample, trainer, base_dir, log_iteration=100, plot_settings_A=plot_settings[3:], plot_settings_B=plot_settings)\n",
        "plot_ABA_callback.call(0)\n",
        "\n",
        "random_sample = [ds_B[i] for i in random.sample(range(len(ds_B)), 4)]\n",
        "plot_BAB_callback = PlotBAB(random_sample, trainer, base_dir, log_iteration=100, plot_settings_A=plot_settings[3:], plot_settings_B=plot_settings)\n",
        "plot_BAB_callback.call(0)\n",
        "\n",
        "callbacks = [plot_ABA_callback, plot_BAB_callback, history_callback, progress_callback, save_callback]\n",
        "# init data loaders\n",
        "B_iterator = loop(DataLoader(ds_B, batch_size=1, shuffle=True, num_workers=4, ))\n",
        "A_iterator = loop(DataLoader(ds_A, batch_size=1, shuffle=True, num_workers=4, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGBeKYNxNiEZ"
      },
      "outputs": [],
      "source": [
        "# start update cycle\n",
        "for it in range(start_it, 10000):\n",
        "    trainer.train()\n",
        "    #\n",
        "    x_a, x_b = next(A_iterator), next(B_iterator)\n",
        "    x_a, x_b = x_a.float().cuda().detach(), x_b.float().cuda().detach()\n",
        "    trainer.discriminator_update(x_a, x_b)\n",
        "    #\n",
        "    x_a, x_b = next(A_iterator), next(B_iterator)\n",
        "    x_a, x_b = x_a.float().cuda().detach(), x_b.float().cuda().detach()\n",
        "    trainer.generator_update(x_a, x_b)\n",
        "    torch.cuda.synchronize()\n",
        "    #\n",
        "    trainer.eval()\n",
        "    with torch.no_grad():\n",
        "      for callback in callbacks:\n",
        "          callback(it)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ITI_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}